<!DOCTYPE html>
<html>

<head>
  <title>D-ID Agents API Demo</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="style-agents.css">
  <link rel="icon" type="image/png" sizes="192x192" href="https://studio.d-id.com/favicon/favicon-192x192.png">
  <!-- adding mic button  -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <!-- adding camera detection -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- <title>Person Detection Video Playback</title> -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <!-- face api -->
  <!-- <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api"></script> -->
</head>

<body>
  <!-- // add camera component
  <video id="camera-stream" width="300" height="300" autoplay muted></video>
  <video id="video-element" width="640" height="480" controls style="display:none;">
    <source src="mrgreen4.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video> -->

  <!-- <script>
    const cameraStream = document.getElementById('camera-stream');
    const videoElement = document.getElementById('video-element');

    // Load the COCO-SSD model
    cocoSsd.load().then(model => {
      // Access the camera
      navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        cameraStream.srcObject = stream;
        cameraStream.onloadedmetadata = () => {
          cameraStream.play();
          detectFrame(cameraStream, model);
        };
      });

      // Detect a person in each frame
      function detectFrame(video, model) {
        model.detect(video).then(predictions => {
          let personDetected = predictions.some(prediction => prediction.class === 'person' && prediction.score > 0.6);

          if (personDetected && videoElement.style.display === "none") {
            // Stop camera stream
            stream.getTracks().forEach(track => track.stop());
            // Show and play the video
            videoElement.style.display = "block";
            videoElement.play();
          } else {
            requestAnimationFrame(() => detectFrame(video, model));
          }
        });
      }
    });
  </script> -->

  <div id="content">

    <!-- <div id="status">
      <h4>Agent Status</h4>
      Agent ID: <label id="agentId-label"></label><br />
      Chat ID: <label id="chatId-label"></label><br />
      <br>
      <h4>WebRTC Connection Status</h4>
      ICE gathering status: <label id="ice-gathering-status-label"></label><br />
      ICE status: <label id="ice-status-label"></label><br />
      Peer connection status: <label id="peer-status-label"></label><br />
      Signaling status: <label id="signaling-status-label"></label><br />
      Streaming status: <label id="streaming-status-label"></label><br />
      <br>
      <div id="buttons">
        <button id="agents-button" type="button">Create new Agent with Knowledge</button>
        <br><br>
        <button id="connect-button" type="button">Connect</button>
        <button id="destroy-button" type="button">Destroy</button>
      </div>
    </div> -->

    <!-- <div id="camera">
      // add camera component 
      <video id="camera-stream" width="300" height="300" autoplay muted></video>

      <script>
        const cameraStream = document.getElementById('camera-stream');
        const videoElement = document.getElementById('video-element');
    
        // Load the COCO-SSD model
        cocoSsd.load().then(model => {
          // Access the camera
          navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
            cameraStream.srcObject = stream;
            cameraStream.onloadedmetadata = () => {
              cameraStream.play();
              detectFrame(cameraStream, model);
            };
          });
    
          // Detect a person in each frame
          function detectFrame(video, model) {
            model.detect(video).then(predictions => {
              let personDetected = predictions.some(prediction => prediction.class === 'person' && prediction.score > 0.6);
    
              if (personDetected && videoElement.style.display === "none") {
                // Stop camera stream
                stream.getTracks().forEach(track => track.stop());
                // Show and play the video
                videoElement.style.display = "block";
                videoElement.play();
              } else {
                requestAnimationFrame(() => detectFrame(video, model));
              }
            });
          }
        });
      </script>
    </div>-->
    

    <div id="video-wrapper">
     
        <div id="camera">
          <!-- // add camera component -->
          <video id="camera-stream" width="100" height="100" autoplay muted></video>
        </div>

        <video id="video-element" width="650" height="1060" object-fit="fill" autoplay loop muted class="animated"></video>
        <video id="video-element2" width="650" height="1060" object-fit="fill" controls style="display:none;">
          <source src="mrgreen4.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        
    </div>

    <script src="camera.js"></script>

 
    <!-- // Detect a person in each frame
   
    function detectFrame(video, model) {
      model.detect(video).then(predictions => {
        let personDetected = predictions.some(prediction => prediction.class === 'person' && prediction.score > 0.1);

        if (personDetected) {
          // Stop camera stream
          stream.getTracks().forEach(track => track.stop());
          // Show and play the video
          videoElement2.style.display = "block";
          videoElement2.play();
        } else {
          requestAnimationFrame(() => detectFrame(video, model));
        }
      });
    } -->

    <!-- <video autoplay muted loop id="myvideo">
       <source src="https://agents-results.d-id.com/auth0|66551130afa963d3b2c704a4/agt_EQEYgniM/idle_1716856950157.mp4">
    </video> -->

    <!-- <div class="chat">
      <h4>Chat History</h4>
      <div id="msgHistory">
      </div>
    </div> -->

  </div>

  <div>
    <div id="spacingtext">
    </div>
    <h3> Ask Mr Green a question </h3> 
    <textarea id="textArea" cols="50" rows="1" maxlength="280"></textarea> 
    <br>
    <button id="connect-button" type="button">Connect</button>
    <button id="start-button" type="button">Send</button> 
    <button id="record-button" type="button" class="mic-button">
       <i class="fas fa-microphone"></i>
    </button>
    <br>

    <!-- Type your message here: -->

    <div id="status">
      <h4>Agent Status</h4>
      Agent ID: <label id="agentId-label"></label><br />
      Chat ID: <label id="chatId-label"></label><br />
      <br>
      <h4>WebRTC Connection Status</h4>
      ICE gathering status: <label id="ice-gathering-status-label"></label><br />
      ICE status: <label id="ice-status-label"></label><br />
      Peer connection status: <label id="peer-status-label"></label><br />
      Signaling status: <label id="signaling-status-label"></label><br />
      Streaming status: <label id="streaming-status-label"></label><br />
      <br>
      <div id="buttons">
        <button id="agents-button" type="button">Create new Agent with Knowledge</button>
        <br><br>
        <!-- <button id="connect-button" type="button">Connect</button> -->
        <button id="destroy-button" type="button">Destroy</button>
      </div>
    </div>
    <br>
    
    <div class="chat">
      <h4>Chat History</h4>
      <div id="msgHistory">
      </div>
    </div>
  </div>

  <script type="module" src="./agents-client-api.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>


</body>

</html>